# Example configuration file for lczero-training
# This file demonstrates all available configuration options with their default values
# and explanations of what each setting controls.

data_loader:
  # File Path Provider - Watches directory for new training data files
  file_path_provider:
    # Directory containing training data files (.gz, .tar, etc.)
    directory: "/path/to/training/data"
    
    # Size of internal file queue (default: 16)
    # Controls how many files can be queued for processing
    queue_capacity: 16

  # Chunk Source Loader - Converts file paths to chunk sources
  chunk_source_loader:
    # Number of worker threads for loading chunks from files (default: 1)
    worker_threads: 1
    
    # Size of output queue for processed chunk sources (default: 16)
    output_queue_size: 16

  # Shuffling Chunk Pool - Manages chunk shuffling and loading with reservoir sampling
  shuffling_chunk_pool:
    # Size of chunk shuffle buffer - REQUIRED FIELD, no default
    # This determines how many chunks are kept in memory for shuffling
    # Larger values provide better randomization but use more memory
    chunk_pool_size: 1000
    
    # Number of threads used during initial startup indexing (default: 4)
    # Higher values speed up startup but use more CPU
    num_startup_indexing_threads: 4
    
    # Number of threads for ongoing indexing operations (default: 4)
    num_indexing_threads: 4
    
    # Number of threads for loading chunk data from disk (default: 4)
    num_chunk_loading_threads: 4
    
    # Size of output queue for shuffled chunks (default: 16)
    output_queue_size: 16

  # Chunk Unpacker - Extracts individual training frames from packed chunks
  chunk_unpacker:
    # Number of worker threads for unpacking chunks (default: 1)
    worker_threads: 1
    
    # Size of output queue for unpacked frames (default: 16)
    output_queue_size: 16

  # Shuffling Frame Sampler - Uses reservoir sampling to randomize frame order
  shuffling_frame_sampler:
    # Number of worker threads for frame sampling (default: 1)
    num_worker_threads: 1
    
    # Size of sampling reservoir per worker thread (default: 1000000)
    # Larger values provide better randomization but use more memory
    # Each thread maintains its own reservoir of this size
    reservoir_size_per_thread: 1000000
    
    # Size of output queue for sampled frames (default: 16)
    output_queue_size: 16

  # Tensor Generator - Converts frames to batched tensors for training
  tensor_generator:
    # Number of worker threads for tensor generation (default: 1)
    worker_threads: 1
    
    # Batch size for generated tensors (default: 1024)
    # This determines how many training examples are grouped together
    # Adjust based on available GPU memory and training requirements
    batch_size: 1024
    
    # Size of output queue for batched tensors (default: 4)
    # Smaller than other queues since tensors are larger
    output_queue_size: 4

# Future configuration sections (not yet implemented):
# 
# training_coordinator:
#   # Configuration for training coordination and scheduling
#   min_chunks_before_training: 100
#   max_training_time_hours: 24
# 
# model:
#   # Neural network architecture configuration
#   blocks: 20
#   channels: 256
#   policy_head_channels: 32
#   value_head_channels: 32
# 
# training:
#   # Training hyperparameters
#   learning_rate: 0.001
#   weight_decay: 0.0001
#   epochs: 10
# 
# export:
#   # Model export configuration  
#   output_directory: "/path/to/export/models"
#   export_format: ["onnx", "lczero"]